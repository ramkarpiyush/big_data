{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80261070",
   "metadata": {},
   "source": [
    "# Working with Different Types of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae51f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 49780)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\piyush.ramkar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"c:\\Users\\piyush.ramkar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"c:\\Users\\piyush.ramkar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"c:\\Users\\piyush.ramkar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"c:\\Users\\piyush.ramkar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pyspark\\accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"c:\\Users\\piyush.ramkar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pyspark\\accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"c:\\Users\\piyush.ramkar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pyspark\\accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"c:\\Users\\piyush.ramkar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pyspark\\serializers.py\", line 594, in read_int\n",
      "    length = stream.read(4)\n",
      "  File \"c:\\Users\\piyush.ramkar\\AppData\\Local\\Programs\\Python\\Python38\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%run \"D:\\GitLocal\\big_data\\Spark\\spark the definitive guide\\my_code\\data_readme.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f3476da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- CustomerID: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.printSchema()\n",
    "df_csv.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7047413c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: d:\\GitLocal\\big_data\\Spark\\spark the definitive guide\\my_code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f02779",
   "metadata": {},
   "source": [
    "# Converting to Spark Types:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8cde53",
   "metadata": {},
   "source": [
    "# lit():\n",
    "- The lit() function in PySpark is used to add a constant (literal) value into a DataFrame column expression.\n",
    "- In PySpark, when you want to add a constant value in a withColumn, select, or when expression, you must wrap it using lit(). This tells PySpark: “This is a constant value, not a column name.\n",
    "- Without lit(), PySpark treats strings or numbers as column names rather than literal values, which leads to errors when the referenced column doesn't exist.\n",
    "- lit() values are not mutable — they are constant (immutable) within the context of a PySpark transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5648cb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "|  5|five|5.0|\n",
      "+---+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df_csv.select(lit(5), lit(\"five\"), lit(5.0)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f312519",
   "metadata": {},
   "source": [
    "# Working with Booleans:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f082bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------------------+\n",
      "|InvoiceNo|Description                  |\n",
      "+---------+-----------------------------+\n",
      "|536366   |HAND WARMER UNION JACK       |\n",
      "|536366   |HAND WARMER RED POLKA DOT    |\n",
      "|536367   |ASSORTED COLOUR BIRD ORNAMENT|\n",
      "|536367   |POPPY'S PLAYHOUSE BEDROOM    |\n",
      "|536367   |POPPY'S PLAYHOUSE KITCHEN    |\n",
      "+---------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_csv.where(col(\"InvoiceNo\") != 536365)\\\n",
    "    .select(\"InvoiceNo\", \"Description\")\\\n",
    "    .show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85cb9557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |2010-12-01 08:26:00|2.55     |17850.0   |United Kingdom|\n",
      "|536365   |71053    |WHITE METAL LANTERN                |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |2010-12-01 08:26:00|2.75     |17850.0   |United Kingdom|\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.where(\"InvoiceNo = 536365\")\\\n",
    "    .show(5, False)\n",
    "\n",
    "df_csv.where(\"536365 <> 536365\")\\\n",
    "    .show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dacc6302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|   Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536544|      DOT|DOTCOM POSTAGE|       1|2010-12-01 14:32:00|   569.77|      null|United Kingdom|\n",
      "|   536592|      DOT|DOTCOM POSTAGE|       1|2010-12-01 17:06:00|   607.49|      null|United Kingdom|\n",
      "+---------+---------+--------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import instr     # instr(column, substring)\n",
    "                                            # Tells you the position (index) of the substring inside the text column.\n",
    "                                            # Returns 0 if not found.\n",
    "                                            # It’s case-sensitive.\n",
    "\n",
    "priceFilter = col(\"UnitPrice\") > 600\n",
    "descriptionFilter = instr(df_csv.Description, \"POSTAGE\") >= 1\n",
    "df_csv.where(df_csv.StockCode.isin(\"DOT\")).where(priceFilter | descriptionFilter).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75f5e51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|  fruit|\n",
      "+-------+\n",
      "| banana|\n",
      "|mangona|\n",
      "+-------+\n",
      "\n",
      "+---------+------+\n",
      "|    fruit|pos_na|\n",
      "+---------+------+\n",
      "|    apple|     0|\n",
      "|   banana|     3|\n",
      "|   grapes|     0|\n",
      "|pineapple|     0|\n",
      "|  mangona|     6|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import instr\n",
    "\n",
    "spark = SparkSession.builder.appName(\"instrExample\").getOrCreate()\n",
    "\n",
    "data = [\n",
    "    (\"apple\",),\n",
    "    (\"banana\",),\n",
    "    (\"grapes\",),\n",
    "    (\"pineapple\",),\n",
    "    (\"mangona\",),\n",
    "]\n",
    "df = spark.createDataFrame(data, [\"fruit\"])\n",
    "\n",
    "df.filter(instr(\"fruit\", \"na\") > 0).show()\n",
    "\n",
    "df.withColumn(\"pos_na\", instr(\"fruit\", \"na\")).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "608e12b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|unitPrice|isExpensive|\n",
      "+---------+-----------+\n",
      "|   569.77|       true|\n",
      "|   607.49|       true|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import instr\n",
    "\n",
    "DOTcodeFilter = col(\"StockCode\") == \"DOT\"\n",
    "priceFilter = col(\"UnitPrice\") > 600\n",
    "descripFilter = instr(col(\"Description\"), \"POSTAGE\") >= 1\n",
    "\n",
    "df_csv.withColumn(\"isExpensive\", DOTcodeFilter & (priceFilter | descripFilter))\\\n",
    "    .where(\"isExpensive\")\\\n",
    "    .select(\"unitPrice\", \"isExpensive\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed49993a",
   "metadata": {},
   "source": [
    "# Working with Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67b654ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr, pow, power\n",
    "\n",
    "fabricatedQuantity = pow(col(\"Quantity\")*col(\"UnitPrice\"),2)+5\n",
    "df_csv.select(expr(\"CustomerId\"), fabricatedQuantity.alias(\"realQuantity\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81aa5978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|CustomerId|      realQuantity|\n",
      "+----------+------------------+\n",
      "|   17850.0|239.08999999999997|\n",
      "|   17850.0|          418.7156|\n",
      "+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.selectExpr(\n",
    "    \"CustomerId\",\n",
    "    \"POWER(Quantity * UnitPrice, 2.0) + 5 AS realQuantity\"\n",
    ").show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8f166",
   "metadata": {},
   "source": [
    "- Rounding:\n",
    "\n",
    "- round:\n",
    "    >- Syntax: round(column, scale=0)\n",
    "    >- where, scale = number of decimal places (default 0).\n",
    "\n",
    "    - Implements round half up (also called \"away from zero\").\n",
    "    - If the fractional part is exactly .5, it rounds up to the nearest integer (or specified scale).\n",
    "\n",
    "- bround\n",
    "    - Behavior: Implements round half even (also called \"banker's rounding\").\n",
    "    - If the fractional part is exactly .5, it rounds to the nearest even number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6ac0d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+\n",
      "|round(2.15, 1)|bround(2.15, 1)|\n",
      "+--------------+---------------+\n",
      "|           2.2|            2.2|\n",
      "|           2.2|            2.2|\n",
      "|           2.2|            2.2|\n",
      "|           2.2|            2.2|\n",
      "|           2.2|            2.2|\n",
      "+--------------+---------------+\n",
      "\n",
      "+--------------+---------------+\n",
      "|round(2.55, 0)|bround(2.55, 0)|\n",
      "+--------------+---------------+\n",
      "|           3.0|            3.0|\n",
      "|           3.0|            3.0|\n",
      "|           3.0|            3.0|\n",
      "|           3.0|            3.0|\n",
      "|           3.0|            3.0|\n",
      "+--------------+---------------+\n",
      "\n",
      "+--------------+---------------+\n",
      "|round(2.85, 0)|bround(2.85, 0)|\n",
      "+--------------+---------------+\n",
      "|           3.0|            3.0|\n",
      "|           3.0|            3.0|\n",
      "|           3.0|            3.0|\n",
      "|           3.0|            3.0|\n",
      "|           3.0|            3.0|\n",
      "+--------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, round, bround\n",
    "\n",
    "df.select(round(lit(\"2.15\"), 1), bround(lit(\"2.15\"), 1)).show()\n",
    "\n",
    "df.select(round(lit(\"2.55\")), bround(lit(\"2.55\"))).show()\n",
    "\n",
    "df.select(round(lit(\"2.85\")), bround(lit(\"2.85\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f3c978b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+--------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|summary|        InvoiceNo|         StockCode|         Description|          Quantity|        InvoiceDate|         UnitPrice|        CustomerID|       Country|\n",
      "+-------+-----------------+------------------+--------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|  count|             3108|              3108|                3098|              3108|               3108|              3108|              1968|          3108|\n",
      "|   mean| 536516.684944841|27834.304044117645|                null| 8.627413127413128|               null| 4.151946589446603|15661.388719512195|          null|\n",
      "| stddev|72.89447869788873|17407.897548583845|                null|26.371821677029203|               null|15.638659854603892|1854.4496996893627|          null|\n",
      "|    min|           536365|             10002| 4 PURPLE FLOCK D...|                -1|2010-12-01 08:26:00|               0.0|           12431.0|     Australia|\n",
      "|    max|          C536548|              POST|ZINC WILLIE WINKI...|                96|2010-12-01 17:35:00|              9.95|           18229.0|United Kingdom|\n",
      "+-------+-----------------+------------------+--------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_csv.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed38ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
